{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SG4 - FBN\n",
    "# Topic: facial expression data preprocess & abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d29d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "dir_present = '...' #present directory\n",
    "source_file = os.walk(dir_present+\"/data/reorg/SG4\") #reorg folder\n",
    "destination_folder = dir_present+\"/data/result\" #result folder\n",
    "path_clean = dir_present+\"/data/clean/SG4\" #clean folder\n",
    "clean_file = os.walk(path_clean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b370d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess Timestamp\n",
    "def process_ts(value):\n",
    "    if isinstance(value, str):  # Check if the value is a string\n",
    "        return int(value.split(':')[-1])  # Split the string and convert the last part to an integer\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Header & Error\n",
    "for path, dir_list, file_list in os.walk(dir_present+\"/data/reorg/SG4\"): #source dir\n",
    "  for file_name in file_list:\n",
    "\n",
    "    filepath = os.path.join(path, file_name)\n",
    "    raw = pd.read_csv(filepath)\n",
    "    raw_data = raw.loc[:,\"Timestamp\":\"Weights[63]\"] # 1 Timestamp + 64 sensor columns\n",
    "    #Timestamp format change\n",
    "    raw_data[\"Timestamp\"] = raw_data[\"Timestamp\"].apply(process_ts)\n",
    "    \n",
    "    # clean data\n",
    "    raw_data.drop_duplicates(subset=\"Timestamp\", keep = 'last', inplace = True)\n",
    "    #raw.dropna(axis = 0, how='any', inplace = True)\n",
    "    raw_data.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    # check error  \n",
    "    raw_data_copy = raw_data.copy()\n",
    "    error_str = [\"error\", \"Error\", \"alxr\", \"ALXR\"]\n",
    "    for index, row in raw_data.iterrows():\n",
    "        for name in raw_data.columns:\n",
    "            value = raw_data.at[index, name]\n",
    "            for element in error_str:\n",
    "                if element in str(value):\n",
    "                    raw_data_copy.loc[index, name:] = raw_data.loc[index-1, name:].apply(lambda x: float(x)) #float\n",
    "\n",
    "    # save in new path\n",
    "    save_clean_path = path_clean + '/' + file_name\n",
    "    raw_data_copy.to_csv(save_clean_path, mode='w', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222dbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build FBN Vector: FBN_list\n",
    "df_FBN = pd.DataFrame(columns = range(7))  \n",
    "\n",
    "for path, dir_list, file_list in os.walk(dir_present+\"/data/clean/SG4\"): #clean dir\n",
    "  for file_name in file_list:\n",
    "    \n",
    "    filepath = os.path.join(path, file_name)\n",
    "    raw = pd.read_csv(filepath)\n",
    "\n",
    "    # get FBN_g \n",
    "    # FBN_g : how many blocks this ts need to be divided into\n",
    "    str2 = file_name.split(\".\")\n",
    "    str3 = str2[0].split(\"_\")\n",
    "    id_list = [int(element) for element in str3]\n",
    "    #\n",
    "    LEN = raw.shape[0]\n",
    "    TIME = (int(raw.at[LEN-1,\"Timestamp\"]) - int(raw.at[0,\"Timestamp\"]))/pow(10,9) \n",
    "    FREQ = int(LEN/TIME) #floor\n",
    "    id_list.append(LEN)\n",
    "    id_list.append(TIME)\n",
    "    id_list.append(FREQ)\n",
    "\n",
    "    df_element = pd.DataFrame(id_list)\n",
    "    df_element = df_element.T\n",
    "    df_FBN = df_FBN.append(df_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count FBN_list based on info dataframe\n",
    "df_FBN.columns = [\"user_id\", \"game_id\", \"round_id\", \"device_id\", \"len\", \"time_slot\", \"frequency\"]\n",
    "FBN_list = []\n",
    "FBN_list_max = []\n",
    "FBN_list_min = []\n",
    "\n",
    "for i in [1.0, 2.0]: #game id list\n",
    "    df_FBN_gi = df_FBN[df_FBN[\"game_id\"] == i]\n",
    "    time_gi = int(np.mean(df_FBN_gi[\"time_slot\"]))\n",
    "    time_gi_max = int(np.max(df_FBN_gi[\"time_slot\"]))\n",
    "    time_gi_min = int(np.min(df_FBN_gi[\"time_slot\"]))\n",
    "    FBN_list.append(time_gi)\n",
    "    FBN_list_max.append(time_gi_max)\n",
    "    FBN_list_min.append(time_gi_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create blank csv\n",
    "df1 = pd.DataFrame(columns = range(7))\n",
    "df1.columns = [\"user_id\", \"game_id\", \"round_id\", \"device_id\", \"time_slot\", \"sample_size\", \"block_number\"]\n",
    "save_info_path = destination_folder + '/SG4_info_FBN_r1.csv'\n",
    "df1.to_csv(save_info_path, index=False, header=True) #default: header=False\n",
    "\n",
    "df2 = pd.DataFrame(columns = range(325)) # 5  + 5 * 64 = 325 (* 64 points in face; w0-w63)\n",
    "df2_str_list = []\n",
    "for j in [\"max\", \"min\", \"mean\", \"std\", \"med\"]:\n",
    "  for i in range(64):\n",
    "    df2_str_list.append(\"w\" + str(i) + \"_\" + j)\n",
    "df2_id_list = [\"user_id\", \"game_id\", \"round_id\", \"device_id\",\"block_id\"] \n",
    "df2_str_list = df2_id_list + df2_str_list \n",
    "df2.columns = df2_str_list\n",
    "save_feat_path = destination_folder + '/SG4_fuse_ts_feature_FBN_r1.csv'  \n",
    "df2.to_csv(save_feat_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba719c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Divide block and abstract the information\n",
    "\n",
    "for path, dir_list, file_list in os.walk(dir_present+\"/data/clean/SG4\"): #clean dir\n",
    "  for file_name in file_list:\n",
    "\n",
    "    filepath = os.path.join(path, file_name)\n",
    "    raw = pd.read_csv(filepath)\n",
    "    raw_data = raw.loc[:,\"Weights[0]\":\"Weights[63]\"] # 64 features\n",
    "\n",
    "    # get FBN_g \n",
    "    # FBN_g : how many blocks this ts need to be divided into\n",
    "    str2 = file_name.split(\".\")\n",
    "    str3 = str2[0].split(\"_\")\n",
    "    id_list = [int(element) for element in str3]\n",
    "    g_id = int(id_list[1])\n",
    "    # FBN_g\n",
    "    FBN_g = FBN_list[g_id-1]\n",
    "\n",
    "    # Build ts blocks\n",
    "    ratio = 1 # ratio:larger ratio (larger block amount), smaller UNIT; \n",
    "    LEN = raw.shape[0]\n",
    "    UNIT = int(raw.shape[0]/(FBN_g * ratio)) #unit: How many records in a block \n",
    "    ts_delta = (int(raw.at[LEN-1, \"Timestamp\"]) - int(raw.at[0, \"Timestamp\"])) / pow(10,9) \n",
    "    df_wr = pd.DataFrame() #store all the block info\n",
    "\n",
    "    # Traverse Blocks in a ts\n",
    "    for i in range(int(FBN_g * ratio)):\n",
    "      \n",
    "      #set block\n",
    "      raw_block = raw_data[UNIT * i : ( UNIT * (i + 1) - 1)]\n",
    "      \n",
    "      #compute statistics\n",
    "      fea_block = [] # 5 statistics\n",
    "      fea_block += list(raw_block.max())\n",
    "      fea_block += list(raw_block.min())\n",
    "      fea_block += list(raw_block.mean())\n",
    "      fea_block += list(raw_block.std())\n",
    "      fea_block += list(raw_block.median())\n",
    "      df_block_fea = pd.DataFrame(fea_block)\n",
    "      df_block_fea = df_block_fea.T\n",
    "      \n",
    "      #combine blocks feature\n",
    "      str2 = file_name.split(\".\")\n",
    "      str3 = str2[0].split(\"_\")\n",
    "      id_list = [int(element) for element in str3]\n",
    "      id_list.append(i)\n",
    "      \n",
    "      id_df = pd.DataFrame(id_list)\n",
    "      id_df = id_df.T\n",
    "      id_df.columns = [\"user_id\", \"game_id\", \"round_id\", \"device_id\", \"block_id\"]\n",
    "      df_block_row = pd.concat([id_df, df_block_fea], axis = 1, join = 'outer')\n",
    "      df_wr = df_wr.append(df_block_row)\n",
    "\n",
    "    # Save One file info\n",
    "    str2 = file_name.split(\".\")\n",
    "    str3 = str2[0].split(\"_\")\n",
    "    id_list = [int(element) for element in str3]\n",
    "\n",
    "    id_list.append(ts_delta) # sec info: how many seconds\n",
    "    id_list.append(LEN) # how many samples\n",
    "    id_list.append(i+1) # how many blocks\n",
    "    id_df = pd.DataFrame(id_list)\n",
    "    id_df = id_df.T\n",
    "    id_df.columns = [\"user_id\", \"game_id\", \"round_id\", \"device_id\", \"time_slot\", \"sample_size\", \"block_number\"]\n",
    "    id_df.to_csv(save_info_path, mode='a', index=False, header=False)\n",
    "    #time_slot: how long for user playing the game: Unit-second\n",
    "    #sample_size:how many ts data\n",
    "    #block_number:timeseries is divided into how many blocks\n",
    "    \n",
    "    # Save file featues\n",
    "    df_wr.to_csv(save_feat_path, mode='a', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
